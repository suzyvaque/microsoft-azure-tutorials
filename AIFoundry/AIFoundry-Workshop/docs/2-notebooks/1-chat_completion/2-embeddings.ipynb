{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ca3e8f66",
      "metadata": {},
      "source": [
        "# üèãÔ∏è Fun with Text and Image Embeddings üçé\n",
        "\n",
        "Welcome to our **Health & Fitness** embeddings notebook! In this tutorial, we'll show you how to:\n",
        "\n",
        "1. **Initialize** an `AIProjectClient` to access your Azure AI Foundry project.\n",
        "2. **Embed text** using `azure-ai-inference` (text embeddings).\n",
        "3. **Embed images** using `azure-ai-inference` (image embeddings).\n",
        "4. **Generate a health-themed image** (simple example) and display it.\n",
        "5. **Use a prompt template** for extra fun.\n",
        "\n",
        "We'll do it all with a playful üçè health theme. Let's jump in!\n",
        "\n",
        "> **Disclaimer**: We're not offering medical advice. This is purely educational & fun.\n",
        "\n",
        "<img src=\"./seq-diagrams/2-embeddings.png\" width=\"30%\"/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffbd2ac6",
      "metadata": {},
      "source": [
        "## 1. Setup & Environment\n",
        "\n",
        "We'll import our libraries, load environment variables for:\n",
        "- `PROJECT_CONNECTION_STRING`: your project connection string.\n",
        "- `MODEL_DEPLOYMENT_NAME`: the name of your model deployment.\n",
        "\n",
        "Install these packages if you haven't already:\n",
        "```bash\n",
        "pip install azure-ai-projects azure-ai-inference azure-identity\n",
        "```\n",
        "Let's begin! üöÄ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50899c96",
      "metadata": {
        "executionInfo": {}
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from pathlib import Path\n",
        "\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.projects import AIProjectClient\n",
        "from azure.ai.inference.models import ImageEmbeddingInput\n",
        "\n",
        "# Load environment variables (optional, if you keep them in a .env file)\n",
        "load_dotenv()\n",
        "\n",
        "# Retrieve from environment or fallback\n",
        "PROJECT_CONNECTION_STRING = os.environ.get(\"PROJECT_CONNECTION_STRING\", \"<your-connection-string>\")\n",
        "MODEL_DEPLOYMENT_NAME = os.environ.get(\"MODEL_DEPLOYMENT_NAME\", \"<your-deployment-name>\")\n",
        "\n",
        "# Initialize project client\n",
        "try:\n",
        "    project_client = AIProjectClient.from_connection_string(\n",
        "        credential=DefaultAzureCredential(),\n",
        "        conn_str=PROJECT_CONNECTION_STRING,\n",
        "    )\n",
        "    print(\"üéâ Successfully created AIProjectClient\")\n",
        "except Exception as e:\n",
        "    print(\"‚ùå Error creating AIProjectClient:\", e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e970dcce",
      "metadata": {},
      "source": [
        "## 2. Text Embeddings\n",
        "\n",
        "We'll call `get_embeddings_client()` to retrieve the embeddings client from our `AIProjectClient`. Then we embed some fun health-themed phrases:\n",
        "\n",
        "- \"üçé An apple a day keeps the doctor away\"\n",
        "- \"üèãÔ∏è 15-minute HIIT workout routine\"\n",
        "- \"üßò Mindful breathing exercises\"\n",
        "\n",
        "This returns numeric vectors representing each phrase in semantic space.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28466a95",
      "metadata": {
        "executionInfo": {}
      },
      "outputs": [],
      "source": [
        "text_phrases = [\n",
        "    \"An apple a day keeps the doctor away üçé\",\n",
        "    \"Quick 15-minute HIIT workout routine üèãÔ∏è\",\n",
        "    \"Mindful breathing exercises üßò\"\n",
        "]\n",
        "\n",
        "try:\n",
        "    with project_client.inference.get_embeddings_client() as embed_client:\n",
        "        response = embed_client.embed(\n",
        "            model=MODEL_DEPLOYMENT_NAME,\n",
        "            input=text_phrases\n",
        "        )\n",
        "\n",
        "        for item in response.data:\n",
        "            vec = item.embedding\n",
        "            sample_str = f\"[{vec[0]:.4f}, {vec[1]:.4f}, ..., {vec[-2]:.4f}, {vec[-1]:.4f}]\"\n",
        "            print(f\"Sentence {item.index}: '{text_phrases[item.index]}':\\n\" \\\n",
        "                  f\"  Embedding length={len(vec)}\\n\" \\\n",
        "                  f\"  Sample: {sample_str}\\n\")\n",
        "except Exception as e:\n",
        "    print(\"‚ùå Error embedding text:\", e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad7b0402",
      "metadata": {},
      "source": [
        "## 3. Prompt Template Example üìù\n",
        "\n",
        "Even though our focus is embeddings, let's quickly show how you'd integrate a **prompt template**. Imagine we want to embed user text but prepend a little system context like ‚ÄúYou are a helpful fitness coach.‚Äù We'll do that here in a minimal way.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78f3e392",
      "metadata": {
        "executionInfo": {}
      },
      "outputs": [],
      "source": [
        "# A basic prompt template (system-style) we'll prepend to user text.\n",
        "TEMPLATE_SYSTEM = (\n",
        "    \"You are HealthFitGPT, a fitness guidance model.\\n\"\n",
        "    \"Please focus on healthy advice and disclaim you're not a doctor.\\n\\n\"\n",
        "    \"User message:\"  # We'll append user message after this.\n",
        ")\n",
        "\n",
        "def embed_with_template(user_text):\n",
        "    \"\"\"Embed user text with a system template in front.\"\"\"\n",
        "    content = TEMPLATE_SYSTEM + user_text\n",
        "    with project_client.inference.get_embeddings_client() as embed_client:\n",
        "        rsp = embed_client.embed(\n",
        "            model=MODEL_DEPLOYMENT_NAME,\n",
        "            input=[content]\n",
        "        )\n",
        "    return rsp.data[0].embedding\n",
        "\n",
        "sample_user_text = \"Can you suggest a quick home workout for busy moms?\"\n",
        "embedding_result = embed_with_template(sample_user_text)\n",
        "print(\"Embedding length:\", len(embedding_result))\n",
        "print(\"First few dims:\", embedding_result[:8])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2571c972",
      "metadata": {},
      "source": [
        "## 4. Image Embeddings\n",
        "\n",
        "Now let's embed an **image**! We'll treat the image as input to a model that returns a vector. The snippet below references a file named `gbb.jpeg` (replace with any local path). In a real scenario, this can be your own photo or user-uploaded image.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "353bbc40",
      "metadata": {
        "executionInfo": {}
      },
      "outputs": [],
      "source": [
        "image_file_path = \"gbb.jpeg\"  # Replace with your local image path!\n",
        "try:\n",
        "    with project_client.inference.get_image_embeddings_client() as img_embed_client:\n",
        "        # Construct input for the image embeddings call\n",
        "        img_input = ImageEmbeddingInput.load(image_file=image_file_path, image_format=\"jpg\")\n",
        "        resp = img_embed_client.embed(\n",
        "            model=MODEL_DEPLOYMENT_NAME,\n",
        "            input=[img_input]\n",
        "        )\n",
        "\n",
        "        for item in resp.data:\n",
        "            vec = item.embedding\n",
        "            snippet = f\"[{vec[0]:.4f}, {vec[1]:.4f}, ..., {vec[-2]:.4f}, {vec[-1]:.4f}]\"\n",
        "            print(f\"Image index={item.index}, length={len(vec)}, sample={snippet}\")\n",
        "except Exception as e:\n",
        "    print(\"‚ùå Error embedding image:\", e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb863ae9",
      "metadata": {},
      "source": [
        "## 5. Generate a Health-Related Image üèÉ\n",
        "\n",
        "Though distinct from embeddings, let's have some fun and **generate** a small health-themed image using the same `project_client`. The actual method name may vary depending on your installed version of `azure-ai-inference`. We'll pretend there's a `get_image_generation_client()` method. We'll pass a simple prompt describing a healthy scenario.\n",
        "\n",
        "We'll then display the returned image inline. (In real usage, you'd handle the raw bytes, save them, or pass them back to your application.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b07b38d6",
      "metadata": {
        "executionInfo": {}
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# This block is pseudo-code / example, depending on your actual method names:\n",
        "def generate_health_image(prompt=\"A simple cartoon of a happy person jogging outdoors\"):\n",
        "    try:\n",
        "        with project_client.inference.get_image_generation_client() as gen_client:\n",
        "            gen_response = gen_client.generate(\n",
        "                model=MODEL_DEPLOYMENT_NAME,\n",
        "                prompt=prompt,\n",
        "                # possibly other params like size, etc.\n",
        "            )\n",
        "            # We'll assume gen_response has a base64 image or raw bytes in .data[0].\n",
        "            # This is just an example structure:\n",
        "            if gen_response.data:\n",
        "                image_bytes = gen_response.data[0].binary  # or .content, .image_bytes, etc.\n",
        "                return image_bytes\n",
        "    except Exception as e:\n",
        "        print(\"‚ùå Error generating image:\", e)\n",
        "    return None\n",
        "\n",
        "# Let's do a quick run\n",
        "generated_img_data = generate_health_image()\n",
        "if generated_img_data:\n",
        "    display(Image(generated_img_data))\n",
        "else:\n",
        "    print(\"(No generated image data. This may be stub code for demonstration.)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3c6dece",
      "metadata": {},
      "source": [
        "## 6. Wrap-Up & Next Steps\n",
        "üéâ We've shown how to:\n",
        "- Set up `AIProjectClient`.\n",
        "- Get **text embeddings**.\n",
        "- Get **image embeddings**.\n",
        "- **Generate** a health-themed image.\n",
        "- Use a **prompt template** for some system context.\n",
        "\n",
        "**Where to go next?**\n",
        "- Explore `azure-ai-evaluation` for evaluating your embeddings.\n",
        "- Use `azure-core-tracing-opentelemetry` for end-to-end telemetry.\n",
        "- Build out a retrieval pipeline to compare similarity of embeddings.\n",
        "\n",
        "Have fun experimenting, and remember: always consult real health professionals for medical advice!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
